{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 525 Assignment 3\n",
    "Sirut Buasai, sbuasai2@wpi.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import json\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertTokenizerFast\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Retrieval and Processing\n",
    "### Process JSON Data Format into Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare load data function for preprocessing\n",
    "def load_data(path):  \n",
    "  # load the json file\n",
    "  with open(path, 'r') as f:\n",
    "    raw_data = json.load(f)\n",
    "\n",
    "  # initialize return lists\n",
    "  ids = []\n",
    "  contexts = []\n",
    "  questions = []\n",
    "  answers = []\n",
    "\n",
    "  # initialize empty answer dict\n",
    "  empty_ans = {'text': '',\n",
    "               'answer_start': 10}\n",
    "\n",
    "  # iterate through the json file and place each data into their respective lists\n",
    "  for data in raw_data['data']:\n",
    "    for topic in data['paragraphs']:\n",
    "      context = topic['context']\n",
    "      for qa in topic['qas']:\n",
    "        question = qa['question']\n",
    "        qid = qa['id']\n",
    "\n",
    "        # if there is no answer, append empty string\n",
    "        if not qa['answers']:\n",
    "          contexts.append(context)\n",
    "          questions.append(question)\n",
    "          answers.append(empty_ans)\n",
    "          ids.append(qid)\n",
    "          \n",
    "        else:\n",
    "          for answer in qa['answers']:\n",
    "            contexts.append(context)\n",
    "            questions.append(question)\n",
    "            answers.append(answer)\n",
    "            ids.append(qid)\n",
    "\n",
    "  # initialize dataframe\n",
    "  df = pd.DataFrame({\n",
    "    'id': ids,\n",
    "    'context': contexts,\n",
    "    'question': questions,\n",
    "    'answer': answers\n",
    "  })\n",
    "\n",
    "  return df\n",
    "\n",
    "# initialize dataset files\n",
    "train_json = 'train-v2.0.json'\n",
    "test_json = 'dev-v2.0.json'\n",
    "\n",
    "# load data\n",
    "train_data = load_data(train_json)\n",
    "test_data = load_data(test_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Subset of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample a subset of train data for faster training\n",
    "train_size = int(0.1*len(train_data))\n",
    "train_data = train_data[:train_size]\n",
    "\n",
    "# sample a subset of test data (keep full size for final predictions)\n",
    "test_size = int(len(test_data))\n",
    "test_data = test_data[:test_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create End Index for Each Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare add end index function for each answer\n",
    "def add_end_idx(answers, contexts):\n",
    "  # get starting and ending index\n",
    "  for answer, context in zip(answers, contexts):\n",
    "    answer_text = answer['text']\n",
    "    start_idx = answer['answer_start']\n",
    "    end_idx = start_idx + len(answer_text)\n",
    "\n",
    "    # auto adjust in case answers length are offset\n",
    "    if context[start_idx:end_idx] == answer_text:\n",
    "      answer['answer_end'] = end_idx\n",
    "\n",
    "    # answers are off by 1\n",
    "    elif context[start_idx-1:end_idx-1] == answer_text:\n",
    "      answer['answer_start'] = start_idx - 1\n",
    "      answer['answer_end'] = end_idx - 1\n",
    "\n",
    "    # answers are off by 2\n",
    "    elif context[start_idx-2:end_idx-2] == answer_text:\n",
    "      answer['answer_start'] = start_idx - 2\n",
    "      answer['answer_end'] = end_idx - 2     # When the gold label is off by two characters\n",
    "\n",
    "# add end index for train and test dataset\n",
    "add_end_idx(train_data['answer'], train_data['context'])\n",
    "add_end_idx(test_data['answer'], test_data['context'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Dataset Based on Context and Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# initialize dataset encodings\n",
    "train_encodings = tokenizer(list(train_data['context']), list(train_data['question']), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(list(test_data['context']), list(test_data['question']), truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Each Answer Starting and Ending Index Positions as Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare add answer index positions to token encodings\n",
    "def add_token_positions(encodings, answers):\n",
    "  # initialize starting and ending encoding positions\n",
    "  starts = []\n",
    "  ends = []\n",
    "\n",
    "  # populate encoding positions\n",
    "  for i in range(len(answers)):\n",
    "    starts.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
    "    ends.append(encodings.char_to_token(i, answers[i]['answer_end'] - 1))\n",
    "\n",
    "    # handle truncated answers\n",
    "    if not starts[-1]:\n",
    "      starts[-1] = tokenizer.model_max_length\n",
    "    if not ends[-1]:\n",
    "      ends[-1] = tokenizer.model_max_length\n",
    "\n",
    "  encodings.update({'starts': starts, 'ends': ends})\n",
    "\n",
    "# add positional tokens to training and testing set\n",
    "add_token_positions(train_encodings, train_data['answer'])\n",
    "add_token_positions(test_encodings, test_data['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Dataloaders for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create custom Dataset class for torch Dataloader\n",
    "class QnA_Dataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, encodings):\n",
    "    self.encodings = encodings\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.encodings.input_ids)\n",
    "\n",
    "# convert dataset to torch Dataset\n",
    "train_dataset = QnA_Dataset(train_encodings)\n",
    "test_dataset = QnA_Dataset(test_encodings)\n",
    "\n",
    "# create the dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning Question and Answering BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create device to force GPU\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# initalize model and optimizer\n",
    "model = BertForQuestionAnswering.from_pretrained(\"bert-base-uncased\")\n",
    "optim = AdamW(model.parameters(), lr=5e-5)\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "# training loop \n",
    "epoch = 5\n",
    "for epoch in range(epoch):\n",
    "  loop = tqdm(train_loader, leave=True)\n",
    "  for batch in loop:\n",
    "    optim.zero_grad()\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    starts = batch['starts'].to(device)\n",
    "    ends = batch['ends'].to(device)\n",
    "    outputs = model(input_ids, attention_mask=attention_mask, start_positions=starts, end_positions=ends)\n",
    "    loss = outputs[0]\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    loop.set_description(f'Epoch {epoch+1}')\n",
    "    loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Question and Answering BERT\n",
    "### Declare Evaluation Functions for SQuAD Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(context, question):\n",
    "  inputs = tokenizer.encode_plus(question, context, return_tensors='pt', truncation=True, max_length=512).to(device)\n",
    "  outputs = model(**inputs)\n",
    "  \n",
    "  answer_start = torch.argmax(outputs[0])  \n",
    "  answer_end = torch.argmax(outputs[1]) + 1 \n",
    "  \n",
    "  answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))\n",
    "  \n",
    "  return answer\n",
    "\n",
    "def normalize_text(s):\n",
    "  \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n",
    "  import string, re\n",
    "  def remove_articles(text):\n",
    "    regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "    return re.sub(regex, \" \", text)\n",
    "  def white_space_fix(text):\n",
    "    return \" \".join(text.split())\n",
    "  def remove_punc(text):\n",
    "    exclude = set(string.punctuation)\n",
    "    return \"\".join(ch for ch in text if ch not in exclude)\n",
    "  def lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "  return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def compute_f1(prediction, truth):\n",
    "  pred_tokens = normalize_text(prediction).split()\n",
    "  truth_tokens = normalize_text(truth).split()\n",
    "  \n",
    "  # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
    "  if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
    "    return int(pred_tokens == truth_tokens)\n",
    "  \n",
    "  common_tokens = set(pred_tokens) & set(truth_tokens)\n",
    "  \n",
    "  # if there are no common tokens then f1 = 0\n",
    "  if len(common_tokens) == 0:\n",
    "    return 0\n",
    "  \n",
    "  prec = len(common_tokens) / len(pred_tokens)\n",
    "  rec = len(common_tokens) / len(truth_tokens)\n",
    "  \n",
    "  return round(2 * (prec * rec) / (prec + rec), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Predictions into JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "test_data['predictions'] = test_data.apply(lambda row: get_prediction(row['context'], row['question']), axis=1)\n",
    "\n",
    "# convert dataframe into json\n",
    "predictions_json = dict(zip(test_data['id'], test_data['predictions']))\n",
    "with open('pred.json', 'w') as f:\n",
    "  json.dump(predictions_json, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 64-bit ('3.9.14')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d50662f09ec6209d433ff0029bf9cc367be01420c8c5568a1e0b3ae42a6d5264"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
